{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqdanalysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstrokedecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simple_stroke_segment\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\jude\\documents\\usa\\masters thesis\\code and experiments\\modules\\qdanalysis\\qdanalysis\\strokedecomposition.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mqdanalysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mprep\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmorphology\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m skeletonize\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_objects\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#skeleton network library\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2 as cv\n",
    "import re\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from qdanalysis.strokedecomposition import simple_stroke_segment\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make generated figures easier to view\n",
    "mpl.rcParams['figure.dpi']=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('CERUG/Writer0909_03-01.ppm'),\n",
       " PosixPath('CERUG/Writer0202_03-02.ppm'),\n",
       " PosixPath('CERUG/Writer0202_01.ppm')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path_name = '../datasets/CERUG'\n",
    "path_name = './CERUG'\n",
    "path = pathlib.Path(path_name)\n",
    "files = [fp for fp in path.iterdir()]\n",
    "files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pathname = str(files[2])\n",
    "parts = pathname.split('\\\\')\n",
    "print(\"parts of filepath: \", parts)\n",
    "filename = parts[-1]\n",
    "print(\"filename: \", filename)\n",
    "\n",
    "re.search(r'(\\d*)_(\\d*)(-\\d*)?', filename)[3] == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer0909_03-01\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Writer0202_03-02\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Writer0202_01\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from skimage.morphology import skeletonize\n",
    "#associative arrays, temp\n",
    "writers = []\n",
    "pages = []\n",
    "page_part = []\n",
    "strokes = []\n",
    "\n",
    "for file in path.iterdir():\n",
    "    filename = file.stem\n",
    "    print(filename)\n",
    "\n",
    "    writer_no, page_no, page_part_no = re.search(r'(\\d*)_(\\d*)-?(\\d*)?', filename).groups()\n",
    "    writers.append(writer_no)\n",
    "    pages.append(page_no)\n",
    "    page_part.append(page_part_no)\n",
    "\n",
    "    #open image and process strokes\n",
    "    kernel_size = (5, 5)\n",
    "    image = cv.imread(str(file), cv.IMREAD_GRAYSCALE)\n",
    "    image = cv.GaussianBlur(image, kernel_size, 1.5)\n",
    "    outfile = './output/' + filename  + '.png'\n",
    "    cv.imwrite(outfile, image)\n",
    "\n",
    "    temp = cv.threshold(image, 0, 1, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)[1]\n",
    "    print(temp)\n",
    "    temp = temp*255\n",
    "    outfile = './output/' + filename + \"_skele_\" + '.png'\n",
    "    \n",
    "    cv.imwrite(outfile, temp)\n",
    "\n",
    "    strokes.append(simple_stroke_segment(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([469,  39])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer_1_stroke_sz = map(lambda x: x.shape, strokes[0])\n",
    "np.array(list(writer_1_stroke_sz)).max(axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "stroke_df = pd.DataFrame(columns=['writer', 'image'])\n",
    "for idx, key in enumerate(writers):\n",
    "    doc_strokes = {\"writer\": [writers[idx]]*len(strokes[idx]), \"image\": strokes[idx]}\n",
    "    \n",
    "    stroke_df = pd.concat([stroke_df, pd.DataFrame(doc_strokes)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://gist.github.com/IdeaKing/11cf5e146d23c5bb219ba3508cca89ec\n",
    "from typing import Tuple\n",
    "def resize_with_pad(image: np.array, \n",
    "                    new_shape: Tuple[int, int], \n",
    "                    padding_color: Tuple[int] = (255, 255, 255)) -> np.array:\n",
    "    \"\"\"Maintains aspect ratio and resizes with padding.\n",
    "    Params:\n",
    "        image: Image to be resized.\n",
    "        new_shape: Expected (width, height) of new image.\n",
    "        padding_color: Tuple in BGR of padding color\n",
    "    Returns:\n",
    "        image: Resized image with padding\n",
    "    \"\"\"\n",
    "    original_shape = (image.shape[1], image.shape[0])\n",
    "    ratio = float(max(new_shape))/max(original_shape)\n",
    "    new_size = tuple([int(x*ratio) for x in original_shape])\n",
    "    image = cv.resize(image, new_size)\n",
    "    delta_w = new_shape[0] - new_size[0]\n",
    "    delta_h = new_shape[1] - new_size[1]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    image = cv.copyMakeBorder(image, top, bottom, left, right, cv.BORDER_CONSTANT, value=padding_color)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 64\n",
    "images_padded = []\n",
    "\n",
    "image_labels = np.ndarray(shape=(0, 2), dtype=float)\n",
    "temp_dict = {'0909': [1., 0.], '0202': [0., 1.]}\n",
    "\n",
    "for idx, stroke_list in enumerate(strokes):\n",
    "    for stroke in stroke_list:\n",
    "        if max(stroke.shape) > size:\n",
    "            continue\n",
    "        \n",
    "        image_labels = np.append(image_labels, np.array(temp_dict[writers[idx]]).reshape(1, 2), axis=0)\n",
    "\n",
    "        stroke_colored = cv.cvtColor(stroke.astype(np.uint8), cv.COLOR_GRAY2RGB)\n",
    "        stroke_padded = resize_with_pad(stroke_colored, (size, size), padding_color=(0, 0, 0))\n",
    "        images_padded.append(stroke_padded.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4625, 64, 64, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train = np.array(images_padded)\n",
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4625, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_labels.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#temp solution to stroke decomp bug\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "\n",
    "height_scores = zscore(size_df['height'])\n",
    "width_scores = zscore(size_df['width'])\n",
    "size_df_filtered = size_df[np.logical_and(np.abs(height_scores) < 3, np.abs(width_scores) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 16:45:03.547160: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-01-30 16:45:03.547957: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-01-30 16:45:03.581859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:65:00.0 name: NVIDIA TITAN RTX computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2024-01-30 16:45:03.581924: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-01-30 16:45:03.583667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-01-30 16:45:03.583765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-01-30 16:45:03.584948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-01-30 16:45:03.585191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-01-30 16:45:03.586368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-01-30 16:45:03.586969: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-01-30 16:45:03.589339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-01-30 16:45:03.589762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-01-30 16:45:03.590889: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-30 16:45:03.593094: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-01-30 16:45:03.593443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:65:00.0 name: NVIDIA TITAN RTX computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2024-01-30 16:45:03.593508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-01-30 16:45:03.593542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-01-30 16:45:03.593563: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-01-30 16:45:03.593583: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-01-30 16:45:03.593603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-01-30 16:45:03.593624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-01-30 16:45:03.593644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-01-30 16:45:03.593665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-01-30 16:45:03.593956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-01-30 16:45:03.593999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-01-30 16:45:04.017979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-01-30 16:45:04.018003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2024-01-30 16:45:04.018008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2024-01-30 16:45:04.018613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21714 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:65:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "from qdanalysis.models import adapt_resnet50\n",
    "\n",
    "model = adapt_resnet50((size, size, 3), 2)\n",
    "model.compile(optimizer='nadam', loss=keras.losses.binary_crossentropy, metrics=['accuracy', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.2179 - accuracy: 0.9170 - mse: 0.0623 - val_loss: 0.7152 - val_accuracy: 0.6984 - val_mse: 0.2438\n",
      "Epoch 2/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.2032 - accuracy: 0.9238 - mse: 0.0569 - val_loss: 0.2329 - val_accuracy: 0.9168 - val_mse: 0.0658\n",
      "Epoch 3/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.2004 - accuracy: 0.9262 - mse: 0.0557 - val_loss: 0.4126 - val_accuracy: 0.8357 - val_mse: 0.1344\n",
      "Epoch 4/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.1927 - accuracy: 0.9254 - mse: 0.0550 - val_loss: 0.5387 - val_accuracy: 0.8000 - val_mse: 0.1724\n",
      "Epoch 5/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.1855 - accuracy: 0.9286 - mse: 0.0517 - val_loss: 0.4282 - val_accuracy: 0.8346 - val_mse: 0.1347\n",
      "Epoch 6/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.1759 - accuracy: 0.9354 - mse: 0.0474 - val_loss: 0.2681 - val_accuracy: 0.8876 - val_mse: 0.0854\n",
      "Epoch 7/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.1709 - accuracy: 0.9386 - mse: 0.0457 - val_loss: 0.4069 - val_accuracy: 0.8324 - val_mse: 0.1323\n",
      "Epoch 8/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.1602 - accuracy: 0.9432 - mse: 0.0417 - val_loss: 0.1860 - val_accuracy: 0.9384 - val_mse: 0.0503\n",
      "Epoch 9/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.1521 - accuracy: 0.9481 - mse: 0.0388 - val_loss: 0.3175 - val_accuracy: 0.8714 - val_mse: 0.0996\n",
      "Epoch 10/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.1486 - accuracy: 0.9478 - mse: 0.0393 - val_loss: 0.2630 - val_accuracy: 0.9016 - val_mse: 0.0783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0e27beb1c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "model.fit(images_train, image_labels, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mastersthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
