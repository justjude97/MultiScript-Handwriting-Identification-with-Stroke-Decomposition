{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2 as cv\n",
    "import re\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from qdanalysis.preprocessing.strokedecomposition import simple_stroke_segment\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make generated figures easier to view\n",
    "mpl.rcParams['figure.dpi']=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('CERUG/Writer0909_03-01.ppm'),\n",
       " PosixPath('CERUG/Writer0202_03-02.ppm'),\n",
       " PosixPath('CERUG/Writer0202_01.ppm')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path_name = '../datasets/CERUG'\n",
    "path_name = './CERUG'\n",
    "path = pathlib.Path(path_name)\n",
    "files = [fp for fp in path.iterdir()]\n",
    "files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pathname = str(files[2])\n",
    "parts = pathname.split('\\\\')\n",
    "print(\"parts of filepath: \", parts)\n",
    "filename = parts[-1]\n",
    "print(\"filename: \", filename)\n",
    "\n",
    "re.search(r'(\\d*)_(\\d*)(-\\d*)?', filename)[3] == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer0909_03-01\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Writer0202_03-02\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Writer0202_01\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from skimage.morphology import skeletonize\n",
    "#associative arrays, temp\n",
    "writers = []\n",
    "pages = []\n",
    "page_part = []\n",
    "strokes = []\n",
    "\n",
    "for file in path.iterdir():\n",
    "    filename = file.stem\n",
    "    print(filename)\n",
    "\n",
    "    writer_no, page_no, page_part_no = re.search(r'(\\d*)_(\\d*)-?(\\d*)?', filename).groups()\n",
    "    writers.append(writer_no)\n",
    "    pages.append(page_no)\n",
    "    page_part.append(page_part_no)\n",
    "\n",
    "    #open image and process strokes\n",
    "    kernel_size = (5, 5)\n",
    "    image = cv.imread(str(file), cv.IMREAD_GRAYSCALE)\n",
    "    image = cv.GaussianBlur(image, kernel_size, 1.5)\n",
    "    outfile = './output/' + filename  + '.png'\n",
    "    cv.imwrite(outfile, image)\n",
    "\n",
    "    temp = cv.threshold(image, 0, 1, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)[1]\n",
    "    print(temp)\n",
    "    temp = temp*255\n",
    "    outfile = './output/' + filename + \"_skele_\" + '.png'\n",
    "    \n",
    "    cv.imwrite(outfile, temp)\n",
    "\n",
    "    strokes.append(simple_stroke_segment(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([469,  39])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer_1_stroke_sz = map(lambda x: x.shape, strokes[0])\n",
    "np.array(list(writer_1_stroke_sz)).max(axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "stroke_df = pd.DataFrame(columns=['writer', 'image'])\n",
    "for idx, key in enumerate(writers):\n",
    "    doc_strokes = {\"writer\": [writers[idx]]*len(strokes[idx]), \"image\": strokes[idx]}\n",
    "    \n",
    "    stroke_df = pd.concat([stroke_df, pd.DataFrame(doc_strokes)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://gist.github.com/IdeaKing/11cf5e146d23c5bb219ba3508cca89ec\n",
    "from typing import Tuple\n",
    "def resize_with_pad(image: np.array, \n",
    "                    new_shape: Tuple[int, int], \n",
    "                    padding_color: Tuple[int] = (255, 255, 255)) -> np.array:\n",
    "    \"\"\"Maintains aspect ratio and resizes with padding.\n",
    "    Params:\n",
    "        image: Image to be resized.\n",
    "        new_shape: Expected (width, height) of new image.\n",
    "        padding_color: Tuple in BGR of padding color\n",
    "    Returns:\n",
    "        image: Resized image with padding\n",
    "    \"\"\"\n",
    "    original_shape = (image.shape[1], image.shape[0])\n",
    "    ratio = float(max(new_shape))/max(original_shape)\n",
    "    new_size = tuple([int(x*ratio) for x in original_shape])\n",
    "    image = cv.resize(image, new_size)\n",
    "    delta_w = new_shape[0] - new_size[0]\n",
    "    delta_h = new_shape[1] - new_size[1]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    image = cv.copyMakeBorder(image, top, bottom, left, right, cv.BORDER_CONSTANT, value=padding_color)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 64\n",
    "images_padded = []\n",
    "\n",
    "image_labels = np.ndarray(shape=(0, 2), dtype=float)\n",
    "temp_dict = {'0909': [1., 0.], '0202': [0., 1.]}\n",
    "\n",
    "for idx, stroke_list in enumerate(strokes):\n",
    "    for stroke in stroke_list:\n",
    "        if max(stroke.shape) > size:\n",
    "            continue\n",
    "        \n",
    "        image_labels = np.append(image_labels, np.array(temp_dict[writers[idx]]).reshape(1, 2), axis=0)\n",
    "\n",
    "        stroke_colored = cv.cvtColor(stroke.astype(np.uint8), cv.COLOR_GRAY2RGB)\n",
    "        stroke_padded = resize_with_pad(stroke_colored, (size, size), padding_color=(0, 0, 0))\n",
    "        images_padded.append(stroke_padded.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4625, 64, 64, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train = np.array(images_padded)\n",
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4625, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_labels.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#temp solution to stroke decomp bug\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "\n",
    "height_scores = zscore(size_df['height'])\n",
    "width_scores = zscore(size_df['width'])\n",
    "size_df_filtered = size_df[np.logical_and(np.abs(height_scores) < 3, np.abs(width_scores) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdanalysis.models import adapt_resnet50\n",
    "\n",
    "model = adapt_resnet50((size, size, 3), 2)\n",
    "model.compile(optimizer='nadam', loss=keras.losses.binary_crossentropy, metrics=['accuracy', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "116/116 [==============================] - 39s 337ms/step - loss: 0.5424 - accuracy: 0.7449 - mse: 0.1974 - val_loss: 0.1969 - val_accuracy: 1.0000 - val_mse: 0.0064\n",
      "Epoch 2/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.5315 - accuracy: 0.7432 - mse: 0.1924 - val_loss: 0.4538 - val_accuracy: 0.8670 - val_mse: 0.1080\n",
      "Epoch 3/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.5292 - accuracy: 0.7459 - mse: 0.1912 - val_loss: 0.2652 - val_accuracy: 0.9924 - val_mse: 0.0226\n",
      "Epoch 4/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.5166 - accuracy: 0.7516 - mse: 0.1854 - val_loss: 0.1906 - val_accuracy: 0.9924 - val_mse: 0.0119\n",
      "Epoch 5/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.5183 - accuracy: 0.7516 - mse: 0.1870 - val_loss: 0.2875 - val_accuracy: 0.9589 - val_mse: 0.0401\n",
      "Epoch 6/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.5092 - accuracy: 0.7576 - mse: 0.1822 - val_loss: 0.3820 - val_accuracy: 0.9005 - val_mse: 0.0795\n",
      "Epoch 7/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.5009 - accuracy: 0.7595 - mse: 0.1778 - val_loss: 0.4356 - val_accuracy: 0.8422 - val_mse: 0.1149\n",
      "Epoch 8/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.4979 - accuracy: 0.7543 - mse: 0.1786 - val_loss: 0.4939 - val_accuracy: 0.7924 - val_mse: 0.1451\n",
      "Epoch 9/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.4960 - accuracy: 0.7627 - mse: 0.1770 - val_loss: 0.3038 - val_accuracy: 0.9232 - val_mse: 0.0615\n",
      "Epoch 10/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.4867 - accuracy: 0.7708 - mse: 0.1711 - val_loss: 0.3807 - val_accuracy: 0.8768 - val_mse: 0.0939\n",
      "Epoch 11/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.4824 - accuracy: 0.7757 - mse: 0.1692 - val_loss: 0.2897 - val_accuracy: 0.9416 - val_mse: 0.0496\n",
      "Epoch 12/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.4770 - accuracy: 0.7765 - mse: 0.1664 - val_loss: 0.2914 - val_accuracy: 0.9351 - val_mse: 0.0497\n",
      "Epoch 13/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.4702 - accuracy: 0.7770 - mse: 0.1636 - val_loss: 0.1917 - val_accuracy: 0.9795 - val_mse: 0.0202\n",
      "Epoch 14/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.4607 - accuracy: 0.7843 - mse: 0.1606 - val_loss: 0.2994 - val_accuracy: 0.9276 - val_mse: 0.0600\n",
      "Epoch 15/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.4514 - accuracy: 0.7903 - mse: 0.1562 - val_loss: 0.2829 - val_accuracy: 0.9362 - val_mse: 0.0538\n",
      "Epoch 16/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.4460 - accuracy: 0.7957 - mse: 0.1530 - val_loss: 0.2487 - val_accuracy: 0.9373 - val_mse: 0.0514\n",
      "Epoch 17/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.4395 - accuracy: 0.8005 - mse: 0.1499 - val_loss: 0.2163 - val_accuracy: 0.9546 - val_mse: 0.0352\n",
      "Epoch 18/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.4270 - accuracy: 0.8035 - mse: 0.1463 - val_loss: 0.3292 - val_accuracy: 0.8930 - val_mse: 0.0825\n",
      "Epoch 19/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.4189 - accuracy: 0.8043 - mse: 0.1429 - val_loss: 0.1452 - val_accuracy: 0.9838 - val_mse: 0.0150\n",
      "Epoch 20/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.4119 - accuracy: 0.8127 - mse: 0.1398 - val_loss: 0.4303 - val_accuracy: 0.8141 - val_mse: 0.1350\n",
      "Epoch 21/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.3992 - accuracy: 0.8178 - mse: 0.1339 - val_loss: 0.2951 - val_accuracy: 0.9114 - val_mse: 0.0703\n",
      "Epoch 22/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.3931 - accuracy: 0.8278 - mse: 0.1311 - val_loss: 0.3471 - val_accuracy: 0.8778 - val_mse: 0.0984\n",
      "Epoch 23/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.3796 - accuracy: 0.8351 - mse: 0.1255 - val_loss: 0.3966 - val_accuracy: 0.8378 - val_mse: 0.1190\n",
      "Epoch 24/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.3749 - accuracy: 0.8289 - mse: 0.1245 - val_loss: 0.5408 - val_accuracy: 0.7568 - val_mse: 0.1896\n",
      "Epoch 25/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.3625 - accuracy: 0.8403 - mse: 0.1186 - val_loss: 0.3042 - val_accuracy: 0.8886 - val_mse: 0.0814\n",
      "Epoch 26/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.3609 - accuracy: 0.8416 - mse: 0.1186 - val_loss: 0.2508 - val_accuracy: 0.9157 - val_mse: 0.0615\n",
      "Epoch 27/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.3435 - accuracy: 0.8532 - mse: 0.1117 - val_loss: 0.1895 - val_accuracy: 0.9503 - val_mse: 0.0408\n",
      "Epoch 28/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.3329 - accuracy: 0.8576 - mse: 0.1078 - val_loss: 0.3113 - val_accuracy: 0.8886 - val_mse: 0.0884\n",
      "Epoch 29/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.3210 - accuracy: 0.8665 - mse: 0.1014 - val_loss: 0.4579 - val_accuracy: 0.7978 - val_mse: 0.1507\n",
      "Epoch 30/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.3126 - accuracy: 0.8659 - mse: 0.0982 - val_loss: 0.2354 - val_accuracy: 0.9124 - val_mse: 0.0647\n",
      "Epoch 31/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.3089 - accuracy: 0.8703 - mse: 0.0978 - val_loss: 0.3821 - val_accuracy: 0.8400 - val_mse: 0.1234\n",
      "Epoch 32/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.2992 - accuracy: 0.8714 - mse: 0.0948 - val_loss: 0.1385 - val_accuracy: 0.9665 - val_mse: 0.0273\n",
      "Epoch 33/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.2913 - accuracy: 0.8814 - mse: 0.0896 - val_loss: 0.5017 - val_accuracy: 0.7632 - val_mse: 0.1786\n",
      "Epoch 34/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.2728 - accuracy: 0.8816 - mse: 0.0837 - val_loss: 0.2275 - val_accuracy: 0.9265 - val_mse: 0.0614\n",
      "Epoch 35/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.2677 - accuracy: 0.8865 - mse: 0.0824 - val_loss: 0.2891 - val_accuracy: 0.8886 - val_mse: 0.0830\n",
      "Epoch 36/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.2616 - accuracy: 0.8914 - mse: 0.0797 - val_loss: 0.3392 - val_accuracy: 0.8649 - val_mse: 0.1038\n",
      "Epoch 37/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.2479 - accuracy: 0.9014 - mse: 0.0735 - val_loss: 0.2906 - val_accuracy: 0.8832 - val_mse: 0.0901\n",
      "Epoch 38/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.2390 - accuracy: 0.9027 - mse: 0.0713 - val_loss: 0.3923 - val_accuracy: 0.8346 - val_mse: 0.1294\n",
      "Epoch 39/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.2367 - accuracy: 0.9084 - mse: 0.0697 - val_loss: 0.2281 - val_accuracy: 0.9114 - val_mse: 0.0664\n",
      "Epoch 40/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.2193 - accuracy: 0.9173 - mse: 0.0615 - val_loss: 0.1827 - val_accuracy: 0.9373 - val_mse: 0.0481\n",
      "Epoch 41/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.2129 - accuracy: 0.9197 - mse: 0.0603 - val_loss: 0.3993 - val_accuracy: 0.8324 - val_mse: 0.1312\n",
      "Epoch 42/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.2127 - accuracy: 0.9162 - mse: 0.0618 - val_loss: 0.5369 - val_accuracy: 0.7795 - val_mse: 0.1789\n",
      "Epoch 43/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.2034 - accuracy: 0.9219 - mse: 0.0583 - val_loss: 0.7001 - val_accuracy: 0.6876 - val_mse: 0.2521\n",
      "Epoch 44/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1942 - accuracy: 0.9286 - mse: 0.0547 - val_loss: 0.2687 - val_accuracy: 0.8897 - val_mse: 0.0813\n",
      "Epoch 45/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1837 - accuracy: 0.9297 - mse: 0.0507 - val_loss: 0.5077 - val_accuracy: 0.7914 - val_mse: 0.1672\n",
      "Epoch 46/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1802 - accuracy: 0.9343 - mse: 0.0493 - val_loss: 0.5091 - val_accuracy: 0.7989 - val_mse: 0.1656\n",
      "Epoch 47/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1721 - accuracy: 0.9392 - mse: 0.0468 - val_loss: 0.4073 - val_accuracy: 0.8303 - val_mse: 0.1332\n",
      "Epoch 48/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1701 - accuracy: 0.9368 - mse: 0.0467 - val_loss: 0.5093 - val_accuracy: 0.8011 - val_mse: 0.1658\n",
      "Epoch 49/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1583 - accuracy: 0.9414 - mse: 0.0411 - val_loss: 0.3628 - val_accuracy: 0.8638 - val_mse: 0.1102\n",
      "Epoch 50/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1511 - accuracy: 0.9449 - mse: 0.0394 - val_loss: 0.2311 - val_accuracy: 0.9232 - val_mse: 0.0652\n",
      "Epoch 51/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1447 - accuracy: 0.9546 - mse: 0.0365 - val_loss: 0.4777 - val_accuracy: 0.8184 - val_mse: 0.1513\n",
      "Epoch 52/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1380 - accuracy: 0.9570 - mse: 0.0325 - val_loss: 0.3256 - val_accuracy: 0.8681 - val_mse: 0.1033\n",
      "Epoch 53/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1385 - accuracy: 0.9511 - mse: 0.0356 - val_loss: 0.3847 - val_accuracy: 0.8605 - val_mse: 0.1152\n",
      "Epoch 54/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1257 - accuracy: 0.9597 - mse: 0.0303 - val_loss: 0.4312 - val_accuracy: 0.8314 - val_mse: 0.1353\n",
      "Epoch 55/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1209 - accuracy: 0.9635 - mse: 0.0285 - val_loss: 0.4176 - val_accuracy: 0.8432 - val_mse: 0.1299\n",
      "Epoch 56/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1142 - accuracy: 0.9643 - mse: 0.0256 - val_loss: 0.3078 - val_accuracy: 0.8811 - val_mse: 0.0923\n",
      "Epoch 57/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1115 - accuracy: 0.9649 - mse: 0.0259 - val_loss: 0.3214 - val_accuracy: 0.8724 - val_mse: 0.1014\n",
      "Epoch 58/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1066 - accuracy: 0.9662 - mse: 0.0247 - val_loss: 0.5869 - val_accuracy: 0.7849 - val_mse: 0.1744\n",
      "Epoch 59/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.1036 - accuracy: 0.9730 - mse: 0.0217 - val_loss: 0.3976 - val_accuracy: 0.8595 - val_mse: 0.1154\n",
      "Epoch 60/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0984 - accuracy: 0.9708 - mse: 0.0217 - val_loss: 0.3855 - val_accuracy: 0.8649 - val_mse: 0.1107\n",
      "Epoch 61/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0933 - accuracy: 0.9724 - mse: 0.0208 - val_loss: 0.5489 - val_accuracy: 0.8054 - val_mse: 0.1626\n",
      "Epoch 62/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0870 - accuracy: 0.9759 - mse: 0.0174 - val_loss: 0.1874 - val_accuracy: 0.9351 - val_mse: 0.0517\n",
      "Epoch 63/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0912 - accuracy: 0.9724 - mse: 0.0200 - val_loss: 0.6637 - val_accuracy: 0.7686 - val_mse: 0.1937\n",
      "Epoch 64/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0770 - accuracy: 0.9841 - mse: 0.0132 - val_loss: 0.3554 - val_accuracy: 0.8757 - val_mse: 0.0986\n",
      "Epoch 65/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0740 - accuracy: 0.9822 - mse: 0.0136 - val_loss: 0.4066 - val_accuracy: 0.8724 - val_mse: 0.1090\n",
      "Epoch 66/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0728 - accuracy: 0.9816 - mse: 0.0137 - val_loss: 0.3464 - val_accuracy: 0.8919 - val_mse: 0.0943\n",
      "Epoch 67/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0670 - accuracy: 0.9838 - mse: 0.0119 - val_loss: 0.4694 - val_accuracy: 0.8432 - val_mse: 0.1368\n",
      "Epoch 68/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0669 - accuracy: 0.9843 - mse: 0.0119 - val_loss: 0.3999 - val_accuracy: 0.8746 - val_mse: 0.1071\n",
      "Epoch 69/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0651 - accuracy: 0.9843 - mse: 0.0121 - val_loss: 0.3656 - val_accuracy: 0.8768 - val_mse: 0.1035\n",
      "Epoch 70/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0592 - accuracy: 0.9862 - mse: 0.0105 - val_loss: 0.4303 - val_accuracy: 0.8703 - val_mse: 0.1139\n",
      "Epoch 71/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0574 - accuracy: 0.9878 - mse: 0.0095 - val_loss: 0.2812 - val_accuracy: 0.9114 - val_mse: 0.0749\n",
      "Epoch 72/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0624 - accuracy: 0.9822 - mse: 0.0125 - val_loss: 0.7882 - val_accuracy: 0.7514 - val_mse: 0.2138\n",
      "Epoch 73/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0561 - accuracy: 0.9878 - mse: 0.0093 - val_loss: 0.3360 - val_accuracy: 0.9059 - val_mse: 0.0808\n",
      "Epoch 74/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0483 - accuracy: 0.9914 - mse: 0.0075 - val_loss: 0.4251 - val_accuracy: 0.8681 - val_mse: 0.1112\n",
      "Epoch 75/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0487 - accuracy: 0.9914 - mse: 0.0074 - val_loss: 0.5017 - val_accuracy: 0.8454 - val_mse: 0.1278\n",
      "Epoch 76/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0445 - accuracy: 0.9908 - mse: 0.0067 - val_loss: 0.5980 - val_accuracy: 0.8141 - val_mse: 0.1600\n",
      "Epoch 77/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0448 - accuracy: 0.9914 - mse: 0.0067 - val_loss: 0.7740 - val_accuracy: 0.7816 - val_mse: 0.1932\n",
      "Epoch 78/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0456 - accuracy: 0.9889 - mse: 0.0079 - val_loss: 0.5867 - val_accuracy: 0.8324 - val_mse: 0.1506\n",
      "Epoch 79/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0411 - accuracy: 0.9941 - mse: 0.0050 - val_loss: 0.5379 - val_accuracy: 0.8411 - val_mse: 0.1419\n",
      "Epoch 80/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0413 - accuracy: 0.9905 - mse: 0.0070 - val_loss: 0.6658 - val_accuracy: 0.8281 - val_mse: 0.1592\n",
      "Epoch 81/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0360 - accuracy: 0.9943 - mse: 0.0049 - val_loss: 0.4140 - val_accuracy: 0.8768 - val_mse: 0.1055\n",
      "Epoch 82/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0413 - accuracy: 0.9908 - mse: 0.0068 - val_loss: 0.5347 - val_accuracy: 0.8530 - val_mse: 0.1306\n",
      "Epoch 83/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0351 - accuracy: 0.9935 - mse: 0.0051 - val_loss: 0.5830 - val_accuracy: 0.8465 - val_mse: 0.1359\n",
      "Epoch 84/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0318 - accuracy: 0.9954 - mse: 0.0041 - val_loss: 0.7782 - val_accuracy: 0.7978 - val_mse: 0.1802\n",
      "Epoch 85/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0352 - accuracy: 0.9935 - mse: 0.0052 - val_loss: 0.3924 - val_accuracy: 0.8811 - val_mse: 0.0986\n",
      "Epoch 86/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0308 - accuracy: 0.9946 - mse: 0.0042 - val_loss: 0.4964 - val_accuracy: 0.8595 - val_mse: 0.1234\n",
      "Epoch 87/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0461 - accuracy: 0.9876 - mse: 0.0098 - val_loss: 0.2835 - val_accuracy: 0.9146 - val_mse: 0.0702\n",
      "Epoch 88/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0481 - accuracy: 0.9884 - mse: 0.0090 - val_loss: 0.6814 - val_accuracy: 0.8270 - val_mse: 0.1600\n",
      "Epoch 89/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0314 - accuracy: 0.9951 - mse: 0.0041 - val_loss: 0.6572 - val_accuracy: 0.8216 - val_mse: 0.1570\n",
      "Epoch 90/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0237 - accuracy: 0.9962 - mse: 0.0030 - val_loss: 0.4724 - val_accuracy: 0.8724 - val_mse: 0.1147\n",
      "Epoch 91/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0226 - accuracy: 0.9978 - mse: 0.0023 - val_loss: 0.4676 - val_accuracy: 0.8659 - val_mse: 0.1124\n",
      "Epoch 92/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0194 - accuracy: 0.9976 - mse: 0.0019 - val_loss: 0.4003 - val_accuracy: 0.8962 - val_mse: 0.0939\n",
      "Epoch 93/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0219 - accuracy: 0.9968 - mse: 0.0028 - val_loss: 0.4809 - val_accuracy: 0.8746 - val_mse: 0.1120\n",
      "Epoch 94/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0237 - accuracy: 0.9959 - mse: 0.0035 - val_loss: 0.5907 - val_accuracy: 0.8314 - val_mse: 0.1458\n",
      "Epoch 95/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0365 - accuracy: 0.9897 - mse: 0.0076 - val_loss: 0.6776 - val_accuracy: 0.8195 - val_mse: 0.1584\n",
      "Epoch 96/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0319 - accuracy: 0.9911 - mse: 0.0066 - val_loss: 1.0252 - val_accuracy: 0.7632 - val_mse: 0.2117\n",
      "Epoch 97/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0384 - accuracy: 0.9908 - mse: 0.0071 - val_loss: 0.7423 - val_accuracy: 0.7881 - val_mse: 0.1780\n",
      "Epoch 98/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0171 - accuracy: 0.9989 - mse: 0.0013 - val_loss: 0.6324 - val_accuracy: 0.8324 - val_mse: 0.1480\n",
      "Epoch 99/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0172 - accuracy: 0.9976 - mse: 0.0021 - val_loss: 0.6920 - val_accuracy: 0.8314 - val_mse: 0.1515\n",
      "Epoch 100/100\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.0146 - accuracy: 0.9989 - mse: 0.0012 - val_loss: 0.6999 - val_accuracy: 0.8346 - val_mse: 0.1493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5c0c69e0d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "model.fit(images_train, image_labels, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mastersthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
